{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43d1f6-3fc3-462d-bf87-38d8fe587eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805c726-7926-42c2-bd79-3d871ce095e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "\n",
    "DATASET_PATH = \"genres_original\"\n",
    "JSON_PATH = \"data_10.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Number of segments: Breaks up the tracks into a number of different segments, this increases the \n",
    "# number of training data to test on the NN\n",
    "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "\n",
    "    # dictionary to store \n",
    "    # mapping: the genre that is defined\n",
    "    # mfcc: the training data, the inputs\n",
    "    # labels: the output that we expect to label the genres (in number form)\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"mfcc\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length) \n",
    "    # THe above value could be 1.2 -> 2 (round to higher integer)\n",
    "\n",
    "    # Loop through all the genres\n",
    "    # Dirpath: path to the folder we are currently in \n",
    "    # DirNames: All names of folders in the dirPath\n",
    "    # FileNames: All the file names in the dirPath\n",
    "    # i: the index, which will be used for the labels \n",
    "    for i, (dirPath, dirNames, fileNames) in enumerate(os.walk(dataset_path)):\n",
    "        # ensure that we're not at the root level\n",
    "        # we are not at the data level \n",
    "        if dirPath is not dataset_path:\n",
    "\n",
    "            # save the semantic label\n",
    "            dirPath_components = dirPath.split(\"/\") # genre/blues => [\"genre\", \"blues\"]\n",
    "            semantic_label = dirPath_components[-1] # This gets the last element in the set\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "\n",
    "            # Go through all the files in the dirPath\n",
    "            # This will process all the files for the specific genre \n",
    "            for f in fileNames:\n",
    "\n",
    "                # Prevent processing of non wav files\n",
    "                if not f.endswith('.wav'):\n",
    "                    continue\n",
    "                \n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirPath, f)\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # Process segments, extract MFCC, and store the data\n",
    "                for s in range(num_segments):\n",
    "                    # Segment logic\n",
    "                    start_sample = num_samples_per_segment * s # s=0 -> 0\n",
    "                    finish_sample = start_sample + num_samples_per_segment # s=0 -> num_samples_per_segment\n",
    "                    \n",
    "                    # Get MFCC\n",
    "                    mfcc = librosa.feature.mfcc(y=signal[start_sample:finish_sample], \n",
    "                                                sr=sr,\n",
    "                                                n_fft=n_fft,\n",
    "                                                n_mfcc=n_mfcc,\n",
    "                                                hop_length=hop_length)\n",
    "\n",
    "                    mfcc = mfcc.T # You want to transpose\n",
    "                    \n",
    "                    # Store the mfcc for segment if it has the expected length\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i - 1)\n",
    "                        print(\"{}, segment: {}\".format(file_path, s + 1))\n",
    "\n",
    "    # Save to Json File\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)\n",
    "    print(\"Finished Processing All Files\")\n",
    "                             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001b830-b0ee-4bb8-ab03-ba609a2d2ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
